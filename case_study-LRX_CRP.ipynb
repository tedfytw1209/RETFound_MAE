{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b38c954-c9b3-41f2-808b-c16d81e7a700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set environment variable to avoid symbolic tracing issues\n",
    "import os\n",
    "os.environ['TIMM_FUSED_ATTN'] = '0'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset\n",
    "from pytorch_grad_cam import run_dff_on_image, GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from typing import List, Callable, Optional\n",
    "\n",
    "# Import XAI methods\n",
    "from baselines.CRP_LXT import CRP_LXT\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageDraw\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088415c1-dba0-4047-aee5-53bc1fabac72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    ViTImageProcessor, ViTForImageClassification,\n",
    "    AutoImageProcessor, EfficientNetForImageClassification,\n",
    "    ResNetForImageClassification, AutoModel\n",
    ")\n",
    "import models_vit as models\n",
    "from util.datasets import TransformWrapper\n",
    "import timm\n",
    "\n",
    "#get model\n",
    "def get_model(task,model,input_size,nb_classes):\n",
    "    if 'ADCon' in task:\n",
    "        id2label = {0: \"control\", 1: \"ad\"}\n",
    "        label2id = {v: k for k, v in id2label.items()}\n",
    "    else:\n",
    "        id2label = {i: f\"class_{i}\" for i in range(nb_classes)}\n",
    "        label2id = {v: k for k, v in id2label.items()}\n",
    "    processor = None\n",
    "    if 'RETFound_mae' in model:\n",
    "        model = models.__dict__['RETFound_mae'](\n",
    "        img_size=input_size,\n",
    "        num_classes=nb_classes,\n",
    "        drop_path_rate=0.2,\n",
    "        global_pool=True,\n",
    "    )\n",
    "    elif 'vit-base-patch16-224' in model:\n",
    "        # ViT-base-patch16-224 preprocessor\n",
    "        model_ = 'google/vit-base-patch16-224'\n",
    "        processor = TransformWrapper(ViTImageProcessor.from_pretrained(model_))\n",
    "        model = ViTForImageClassification.from_pretrained(\n",
    "            model_,\n",
    "            image_size=input_size, #Not in tianhao code, default 224\n",
    "            num_labels=nb_classes,\n",
    "            hidden_dropout_prob=0.0, #Not in tianhao code, default 0.0\n",
    "            attention_probs_dropout_prob=0.0, #Not in tianhao code, default 0.0\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            ignore_mismatched_sizes=True,\n",
    "            attn_implementation=\"eager\",      # ← key line\n",
    "        )\n",
    "        model.config.return_dict = True\n",
    "        model.config.output_attentions = True\n",
    "    elif 'timm_efficientnet-b4' in model:\n",
    "        model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=nb_classes)\n",
    "        processor  = transforms.Compose([\n",
    "            transforms.Resize((380,380)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "        ])\n",
    "    elif 'ResNet-50' in model:\n",
    "        model_name = 'microsoft/resnet-50'\n",
    "        processor = TransformWrapper(AutoImageProcessor.from_pretrained(model_name))\n",
    "        model = ResNetForImageClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=nb_classes,\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        model.config.return_dict = True\n",
    "        model.config.output_attentions = True\n",
    "\n",
    "    return model, processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8342d-4985-40fc-b2da-68c18e48cf25",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f0a85-078e-4a03-a4f7-57bf8778c49c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# task and dataset\n",
    "#Task_list = ['ADCon','DME']\n",
    "IMG_MASK = True\n",
    "HEATMAP_MASK = False\n",
    "DRAW_LAYER = True\n",
    "Thickness_DIR = \"/orange/ruogu.fang/tienyuchang/IRB2024_OCT_thickness/Data/\"\n",
    "Thickness_CSV = \"/orange/ruogu.fang/tienyuchang/IRB2024_OCT_thickness/thickness_map.csv\"\n",
    "Task_list = ['DME']\n",
    "dataset_fname = 'sampled_labels01.csv'\n",
    "dataset_dir = '/blue/ruogu.fang/tienyuchang/OCT_EDA'\n",
    "img_p_fmt = \"label_%d/%s\" #label index and oct_img name\n",
    "\n",
    "# model\n",
    "Model_root = \"/blue/ruogu.fang/tienyuchang/RETFound_MAE/output_dir\"\n",
    "Model_fname = \"checkpoint-best.pth\"\n",
    "Model_list = ['ResNet-50', 'timm_efficientnet-b4', 'vit-base-patch16-224', 'RETFound_mae']\n",
    "ADCon_finetuned = [\n",
    "    \"ad_control_detect_data-IRB2024v5_ADCON_DL_data-all-resnet-50-OCT-defaulteval---bal_sampler-/\",\n",
    "    \"ad_control_detect_data-IRB2024v5_ADCON_DL_data-all-timm_efficientnet-b4-OCT-defaulteval---bal_sampler-/\",\n",
    "    \"ad_control_detect_data-IRB2024v5_ADCON_DL_data-all-vit-base-patch16-224-OCT-defaulteval---bal_sampler-/\",\n",
    "    \"ad_control_detect_data-IRB2024v5_ADCON_DL_data-all-RETFound_mae-OCT-defaulteval---bal_sampler-/\"\n",
    "]\n",
    "DME_finetuned = [\n",
    "    \"DME_binary_all_split-IRB2024_v5-all-microsoft/resnet-50-OCT-bs16ep50lr5e-4optadamw-defaulteval-trsub0--/\",\n",
    "    \"DME_binary_all_split-IRB2024_v5-all-timm_efficientnet-b4-OCT-bs16ep50lr5e-4optadamw-defaulteval-trsub0--/\",\n",
    "    \"DME_binary_all_split-IRB2024_v5-all-google/vit-base-patch16-224-in21k-OCT-bs16ep50lr5e-4optadamw-defaulteval-trsub0--/\",\n",
    "    \"DME_binary_all_split-IRB2024_v5-all-RETFound_mae_natureOCT-OCT-bs16ep50lr5e-4optadamw-roc_auceval-trsub0--/\"\n",
    "]\n",
    "Model_root = \"/orange/ruogu.fang/tienyuchang/RETfound_results\"\n",
    "DME_finetuned_masked = [\n",
    "    \"DME_binary_all_split-IRB2024_v5-all-microsoft/resnet-50-OCT-bs16ep50lr5e-4optadamw-defaulteval-trsub0---add_mask---train_no_aug/\",\n",
    "    \"DME_binary_all_split-IRB2024_v5-all-timm_efficientnet-b4-OCT-bs16ep50lr5e-4optadamw-defaulteval-trsub0---add_mask---train_no_aug/\",\n",
    "    \"DME_binary_all_split-IRB2024_v5-all-google/vit-base-patch16-224-in21k-OCT-bs16ep50lr5e-4optadamw-defaulteval-trsub0---add_mask---train_no_aug/\",\n",
    "    \"DME_binary_all_split-IRB2024_v5-all-RETFound_mae_natureOCT-OCT-bs16ep50lr5e-4optadamw-defaulteval-trsub0---add_mask---train_no_aug/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3009084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mask function\n",
    "def masked_img_func(img, mask_slice):\n",
    "    binary_mask = np.zeros_like(img, dtype=np.uint8)\n",
    "    for i in range(mask_slice.shape[0]-1):\n",
    "        upper = mask_slice[i].astype(int)\n",
    "        lower = mask_slice[i+1].astype(int)\n",
    "        for x in range(img.shape[1]):\n",
    "            binary_mask[upper[x]:lower[x], x] = 1\n",
    "\n",
    "    # 套用 mask (把 mask=0 的地方設為 0)\n",
    "    masked_img = img.copy()\n",
    "    masked_img[binary_mask == 0] = 0\n",
    "\n",
    "    return masked_img\n",
    "\n",
    "# Data loading and preprocessing functions\n",
    "def load_sample_data(task, num_sample=-1):\n",
    "    \"\"\"Load sample images for a given task\"\"\"\n",
    "    df = pd.read_csv(os.path.join(dataset_dir, \"%s_sampled\"%task, dataset_fname))\n",
    "    if IMG_MASK or HEATMAP_MASK:\n",
    "        masked_df = pd.read_csv(Thickness_CSV)\n",
    "        masked_df = masked_df.rename(columns={'OCT':'folder'}).dropna(subset=['Surface Name'])\n",
    "        df = df.merge(masked_df,on='folder',how='inner').reset_index(drop=True)\n",
    "        print('After adding mask, data len: ', df.shape[0])\n",
    "    task_df = df[df['label'].isin([0, 1])]  # Adjust based on actual DME labels\n",
    "    # Sample random images\n",
    "    if num_sample > 0:\n",
    "        task_df = task_df.sample(n=num_sample, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        task_df = task_df.reset_index(drop=True)\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    filenames = []\n",
    "    mask_slices = []\n",
    "    \n",
    "    for _, row in task_df.iterrows():\n",
    "        # Extract just the filename from oct_img\n",
    "        filename = os.path.basename(row['OCT']) if isinstance(row['OCT'], str) else row['OCT']\n",
    "        img_path = os.path.join(dataset_dir, \"%s_sampled\"%task, img_p_fmt % (row['label'], filename))\n",
    "        if os.path.exists(img_path):\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                if IMG_MASK or HEATMAP_MASK:\n",
    "                    mask_path = os.path.join(Thickness_DIR, row['folder'], row['Surface Name'])\n",
    "                    mask = np.load(mask_path) # (Layer, slice, W)\n",
    "\n",
    "                    # 假設我們要套用其中某一 slice 的 mask，例如 slice_index = 13\n",
    "                    slice_index = int(os.path.basename(img_path).split(\"_\")[-1].split(\".\")[0])  # 從檔名抓 13\n",
    "                    mask_slice = mask[:, slice_index, :]  # shape: (Layer, W)\n",
    "                    mask_slices.append(mask_slice)\n",
    "                else:\n",
    "                    mask_slices.append(None)\n",
    "                    \n",
    "                if IMG_MASK:\n",
    "                    img_np = np.array(img)  # Convert PIL image to numpy array\n",
    "                    masked_img_np = masked_img_func(img_np, mask_slice)\n",
    "                    masked_img = Image.fromarray(masked_img_np)\n",
    "                    images.append(masked_img)\n",
    "                else:\n",
    "                    images.append(img)\n",
    "                labels.append(row['label'])\n",
    "                # Store filename without extension for directory naming\n",
    "                image_name = os.path.splitext(filename)[0]\n",
    "                filenames.append(image_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "    return images, labels, filenames, mask_slices\n",
    "\n",
    "def preprocess_image(image, processor=None, input_size=224, device=None, dtype=torch.float32):\n",
    "    assert isinstance(image, Image.Image), f\"expect PIL.Image, got {type(image)}\"\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if processor is not None:\n",
    "        # A) 先尝试“直接可调用”形式（多数 timm/torchvision transform）\n",
    "        try:\n",
    "            out = processor(image)\n",
    "            if isinstance(out, torch.Tensor):\n",
    "                x = out\n",
    "                if x.ndim == 3:  # [C,H,W] -> [1,C,H,W]\n",
    "                    x = x.unsqueeze(0)\n",
    "                return x.to(device=device, dtype=dtype)\n",
    "            if isinstance(out, dict) and \"pixel_values\" in out:\n",
    "                x = out[\"pixel_values\"]\n",
    "                if isinstance(x, np.ndarray):\n",
    "                    x = torch.from_numpy(x)\n",
    "                if x.ndim == 3:\n",
    "                    x = x.unsqueeze(0)\n",
    "                return x.to(device=device, dtype=dtype)\n",
    "        except TypeError:\n",
    "            pass\n",
    "\n",
    "        # B) 再尝试 HuggingFace 风格（不使用 images= 关键字）\n",
    "        try:\n",
    "            out = processor(image, return_tensors=\"pt\")\n",
    "            if isinstance(out, dict) and \"pixel_values\" in out:\n",
    "                x = out[\"pixel_values\"]  # [1,3,H,W]\n",
    "                return x.to(device=device, dtype=dtype)\n",
    "            if isinstance(out, torch.Tensor):\n",
    "                x = out\n",
    "                if x.ndim == 3:\n",
    "                    x = x.unsqueeze(0)\n",
    "                return x.to(device=device, dtype=dtype)\n",
    "        except TypeError:\n",
    "            pass\n",
    "\n",
    "        # C) 某些实现仅接受列表\n",
    "        for attempt in (lambda: processor([image], return_tensors=\"pt\"),\n",
    "                        lambda: processor([image])):\n",
    "            try:\n",
    "                out = attempt()\n",
    "                if isinstance(out, dict) and \"pixel_values\" in out:\n",
    "                    x = out[\"pixel_values\"]\n",
    "                    if isinstance(x, np.ndarray):\n",
    "                        x = torch.from_numpy(x)\n",
    "                    return x.to(device=device, dtype=dtype)\n",
    "                if isinstance(out, torch.Tensor):\n",
    "                    x = out\n",
    "                    if x.ndim == 3:\n",
    "                        x = x.unsqueeze(0)\n",
    "                    return x.to(device=device, dtype=dtype)\n",
    "            except TypeError:\n",
    "                pass\n",
    "\n",
    "    # D) 回退：标准 ImageNet 预处理\n",
    "    fallback = transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.ToTensor(),  # [0,1]\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    x = fallback(image)            # [3,H,W]\n",
    "    x = x.unsqueeze(0)             # [1,3,H,W]\n",
    "    return x.to(device=device, dtype=dtype)\n",
    "\n",
    "#test dataset\n",
    "dme_imgs, dme_labels, dme_img_names, dme_mask_slices = load_sample_data('DME',-1)\n",
    "print(len(dme_imgs))\n",
    "print(dme_imgs[0])\n",
    "print(dme_labels)\n",
    "# 顯示\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title(\"OCT slice\")\n",
    "plt.imshow(dme_imgs[0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871cd5db-f6fc-4245-8561-11b9b9e89f41",
   "metadata": {},
   "source": [
    "# Model and XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdfdc79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load trained models function\n",
    "def load_trained_model(task, model_name, input_size=224, nb_classes=2):\n",
    "    \"\"\"Load a trained model for a specific task\"\"\"\n",
    "    model, processor = get_model(task, model_name, input_size, nb_classes)\n",
    "    \n",
    "    # Load model weights based on task and model\n",
    "    if task == 'ADCon':\n",
    "        model_paths = ADCon_finetuned\n",
    "    elif task == 'DME':\n",
    "        if IMG_MASK or HEATMAP_MASK:\n",
    "            model_paths = DME_finetuned_masked\n",
    "        else:\n",
    "            model_paths = DME_finetuned\n",
    "    else:\n",
    "        print(f\"Unknown task: {task}\")\n",
    "        model.eval()\n",
    "        return model, processor\n",
    "    \n",
    "    model_idx = Model_list.index(model_name)\n",
    "    model_dir = model_paths[model_idx]\n",
    "    model_path = os.path.join(Model_root, model_dir, Model_fname)\n",
    "    \n",
    "    # Load finetuned model if specified (following main_XAI_evaluation.py pattern)\n",
    "    if model_path and model_path != '':\n",
    "        if os.path.exists(model_path):\n",
    "            try:\n",
    "                # Load checkpoint\n",
    "                if model_path.startswith('https'):\n",
    "                    checkpoint = torch.hub.load_state_dict_from_url(\n",
    "                        model_path, map_location='cpu', check_hash=True)\n",
    "                else:\n",
    "                    checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)\n",
    "                \n",
    "                # Extract model state dict\n",
    "                if 'model' in checkpoint:\n",
    "                    checkpoint_model = checkpoint['model']\n",
    "                else:\n",
    "                    checkpoint_model = checkpoint\n",
    "                \n",
    "                # Load with strict=False to handle potential mismatches\n",
    "                model.load_state_dict(checkpoint_model, strict=False)\n",
    "                print(f\"Resume checkpoint {model_path} for {model_name} on {task}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading model {model_name} for {task}: {e}\")\n",
    "                print(\"Using pretrained weights instead\")\n",
    "        else:\n",
    "            print(f\"Model path not found: {model_path}\")\n",
    "            print(f\"Using pretrained weights for {model_name} on {task}\")\n",
    "    else:\n",
    "        print(f\"No checkpoint specified for {model_name} on {task}, using pretrained weights\")\n",
    "    \n",
    "    model.eval()\n",
    "    return model, processor\n",
    "'''\n",
    "#Model_list = ['ResNet-50', 'timm_efficientnet-b4', 'vit-base-patch16-224', 'RETFound_mae']\n",
    "model_list = ['RETFound_mae']\n",
    "for model_name in model_list:\n",
    "    model, processor = load_trained_model('DME', model_name, 224)\n",
    "    print(model)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00dd935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XAI Methods Implementation\n",
    "class XAIGenerator:\n",
    "    def __init__(self, model, model_name, input_size=224):\n",
    "        self.model = model\n",
    "        self.model_name = model_name\n",
    "        self.input_size = input_size\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # Initialize XAI methods\n",
    "        self.init_xai_methods()\n",
    "    \n",
    "    def get_model_specific_config(self):\n",
    "        \"\"\"Get model-specific configuration for XAI methods\"\"\"\n",
    "        config = {\n",
    "            'patch_size': 14,\n",
    "            'gpu_batch': 1,\n",
    "            'attention_layers': 12\n",
    "        }\n",
    "        \n",
    "        # Model-specific configurations\n",
    "        if 'resnet' in self.model_name.lower():\n",
    "            config.update({\n",
    "                'patch_size': 7,  # ResNet has different spatial resolution\n",
    "                'gpu_batch': 1,  # ResNet can handle larger batches\n",
    "            })\n",
    "        elif 'efficientnet' in self.model_name.lower():\n",
    "            config.update({\n",
    "                'patch_size': 7,  # EfficientNet spatial resolution\n",
    "                'gpu_batch': 1,\n",
    "            })\n",
    "        elif 'vit' in self.model_name.lower():\n",
    "            config.update({\n",
    "                'patch_size': 16,  # ViT patch size\n",
    "                'gpu_batch': 1,\n",
    "                'attention_layers': 12,  # Standard ViT-Base layers\n",
    "            })\n",
    "        elif 'retfound' in self.model_name.lower():\n",
    "            config.update({\n",
    "                'patch_size': 16,  # RETFound uses ViT architecture\n",
    "                'gpu_batch': 1,\n",
    "                'attention_layers': 12,\n",
    "            })\n",
    "        \n",
    "        return config\n",
    "    \n",
    "    def init_xai_methods(self):\n",
    "        \"\"\"Initialize all XAI methods with model-specific configurations\"\"\"\n",
    "        \n",
    "        # CRP_LXT with model-specific batch size\n",
    "        # Reduce batch for memory-heavy models\n",
    "        self.crp_lxt = CRP_LXT(\n",
    "            self.model, \n",
    "            self.model_name,\n",
    "            img_size=(self.input_size, self.input_size)\n",
    "        )\n",
    "        print(f\"✓ CRP_LXT initialized for {self.model_name}\")\n",
    "    \n",
    "    def generate_crp_lxt(self, image_tensor, target_class=None):\n",
    "        \"\"\"Generate CRP_LXT heatmap\"\"\"\n",
    "        if self.crp_lxt is None:\n",
    "            return None\n",
    "        image_tensor = image_tensor.to(self.device)\n",
    "\n",
    "        if target_class is None:\n",
    "            # Get predicted class\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(image_tensor)\n",
    "                target_class = outputs.argmax(dim=1).item()\n",
    "\n",
    "        heatmaps = self.crp_lxt(image_tensor, target_class)\n",
    "        return heatmaps\n",
    "    \n",
    "    def generate_all_heatmaps(self, image_tensor, target_class=None):\n",
    "        \"\"\"Generate all available heatmaps for an image\"\"\"\n",
    "        heatmaps = {}\n",
    "            \n",
    "        # CRP_LXT\n",
    "        crp_lxt_map = self.generate_crp_lxt(image_tensor, target_class)\n",
    "        if crp_lxt_map is not None:\n",
    "            heatmaps['CRP_LXT'] = crp_lxt_map\n",
    "        \n",
    "        return heatmaps\n",
    "    \n",
    "#test\n",
    "'''\n",
    "for model_name in Model_list:\n",
    "    model, processor = load_trained_model('DME', model_name, 224)\n",
    "    XAIGenerator(model, model_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014e84d-2ce2-4ad3-96ab-ada47bb0c0d2",
   "metadata": {},
   "source": [
    "# Run Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b602e586-260b-45d3-a1ce-7e20eec35fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualization functions\n",
    "def masked_heatmap_func(heatmap, mask_slice):\n",
    "    if heatmap is None:\n",
    "        return None\n",
    "    \n",
    "    binary_mask = np.zeros_like(heatmap, dtype=np.uint8)\n",
    "    for i in range(mask_slice.shape[0]-1):\n",
    "        upper = mask_slice[i].astype(int)\n",
    "        lower = mask_slice[i+1].astype(int)\n",
    "        for x in range(heatmap.shape[1]):\n",
    "            binary_mask[upper[x]:lower[x], x] = 1\n",
    "\n",
    "    # 套用 mask (把 mask=0 的地方設為 0)\n",
    "    masked_heatmap = heatmap.copy()\n",
    "    masked_heatmap[binary_mask == 0] = 0\n",
    "\n",
    "    return masked_heatmap\n",
    "\n",
    "def add_layer_line(overlay, mask_slice, width=1, cmap_name=\"rainbow\"):\n",
    "    # Convert to PIL.Image if needed\n",
    "    if isinstance(overlay, np.ndarray):\n",
    "        if overlay.dtype != np.uint8:\n",
    "            overlay = np.clip(overlay * 255, 0, 255).astype(np.uint8)\n",
    "        overlay_img = Image.fromarray(overlay)\n",
    "    else:\n",
    "        overlay_img = overlay.convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(overlay_img)\n",
    "    n_layers, W = mask_slice.shape\n",
    "    xs = np.arange(W)\n",
    "    # Generate rainbow colors for each layer\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "    colors = (np.array([cmap(i / max(1, n_layers - 1))[:3] for i in range(n_layers)]) * 255).astype(int)\n",
    "    # Draw each layer line\n",
    "    for i in range(n_layers):\n",
    "        ys = np.nan_to_num(mask_slice[i].astype(float), nan=0.0)\n",
    "        ys = np.clip(ys, 0, overlay_img.height - 1)\n",
    "        points = list(zip(xs, ys))\n",
    "        color = tuple(colors[i])\n",
    "        draw.line(points, fill=color, width=width)\n",
    "\n",
    "    return overlay_img\n",
    "\n",
    "def normalize_heatmap(heatmap):\n",
    "    \"\"\"Normalize heatmap to 0-1 range\"\"\"\n",
    "    if heatmap is None:\n",
    "        return None\n",
    "    \n",
    "    heatmap = np.array(heatmap)\n",
    "    if heatmap.max() == heatmap.min():\n",
    "        return np.zeros_like(heatmap)\n",
    "    \n",
    "    return (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
    "\n",
    "def overlay_heatmap_on_image(image, heatmap, mask_slice = None, alpha=0.4, colormap='jet'):\n",
    "    \"\"\"Return uint8 RGB overlay, shape (H,W,3).\"\"\"\n",
    "\n",
    "    if heatmap is None:\n",
    "        # 保證回傳 (H,W,3) uint8\n",
    "        if isinstance(image, Image.Image):\n",
    "            img = np.array(image)\n",
    "        else:\n",
    "            img = np.array(image)\n",
    "        if img.ndim == 2:                 # 灰階 → RGB\n",
    "            img = np.repeat(img[..., None], 3, axis=-1)\n",
    "        if img.shape[-1] == 4:            # RGBA → RGB\n",
    "            img = img[..., :3]\n",
    "        if img.dtype != np.uint8:\n",
    "            img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "        return img\n",
    "    \n",
    "    if HEATMAP_MASK and mask_slice is not None:\n",
    "        heatmap = masked_heatmap_func(heatmap, mask_slice)\n",
    "\n",
    "    # 1) 統一 image → RGB uint8\n",
    "    img = np.array(image if not isinstance(image, Image.Image) else np.array(image))\n",
    "    if img.ndim == 2:\n",
    "        img = np.repeat(img[..., None], 3, axis=-1)\n",
    "    if img.shape[-1] == 4:\n",
    "        img = img[..., :3]\n",
    "    if img.dtype != np.uint8:\n",
    "        # 若是 0–1，乘回 255；否則直接裁切/轉型\n",
    "        mx = float(img.max()) if img.size else 1.0\n",
    "        if mx <= 1.0:\n",
    "            img = (np.clip(img, 0.0, 1.0) * 255.0).astype(np.uint8)\n",
    "        else:\n",
    "            img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    H, W = img.shape[:2]\n",
    "\n",
    "    # 2) 統一 heatmap → 2D float [0,1]\n",
    "    hm = heatmap\n",
    "    if \"torch\" in str(type(hm)):\n",
    "        hm = hm.detach().float().cpu().numpy()\n",
    "    hm = np.array(hm)\n",
    "    hm = np.squeeze(hm)                   # (H,W) 最佳\n",
    "    if hm.ndim == 3 and hm.shape[-1] == 3:\n",
    "        hm = hm.mean(axis=-1)             # 轉成單通道\n",
    "    if hm.ndim != 2:\n",
    "        raise ValueError(f\"heatmap must be 2D after squeeze; got {hm.shape}\")\n",
    "    # normalize to [0,1]\n",
    "    hm = hm.astype(np.float32)\n",
    "    ptp = hm.max() - hm.min()\n",
    "    hm = (hm - hm.min()) / (ptp + 1e-12)\n",
    "\n",
    "    # 3) resize heatmap 到影像大小\n",
    "    hm_resized = cv2.resize(hm, (W, H), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # 4) 上 colormap → 得到 RGBA，再取前 3 個通道 (RGB)\n",
    "    cmap = plt.get_cmap(colormap)\n",
    "    hm_rgb = cmap(hm_resized)[..., :3].astype(np.float32)   # (H,W,3), 0–1\n",
    "\n",
    "    # 5) 影像轉 0–1，做疊加\n",
    "    img_rgb = img.astype(np.float32) / 255.0\n",
    "    overlay = alpha * hm_rgb + (1.0 - alpha) * img_rgb\n",
    "    overlay = np.clip(overlay, 0.0, 1.0)\n",
    "\n",
    "    return (overlay * 255.0).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "596566fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Updated function with new directory structure for heatmap saving\n",
    "def generate_comprehensive_heatmaps_v2(num_samples=3,task_list=Task_list,model_list=Model_list,heatmap_dir=\"./heatmap_results\"):\n",
    "    \"\"\"Generate heatmaps for all task-model combinations with new directory structure\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    input_size = 224\n",
    "    \n",
    "    print(\"Starting comprehensive heatmap generation...\")\n",
    "    print(f\"Tasks: {task_list}\")\n",
    "    print(f\"Models: {model_list}\")\n",
    "    print(f\"Samples per task: {num_samples}\")\n",
    "    \n",
    "    for task in task_list:\n",
    "        print(f\"\\n=== Processing Task: {task} ===\")\n",
    "        results[task] = {}\n",
    "        \n",
    "        # Load sample data for this task (now returns filenames too)\n",
    "        try:\n",
    "            images, labels, filenames, mask_slices = load_sample_data(task, num_samples)\n",
    "            print(f\"Loaded {len(images)} images for {task}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data for {task}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        for model_name in model_list:\n",
    "            print(f\"\\n--- Processing Model: {model_name} ---\")\n",
    "            # Load trained model\n",
    "            model, processor = load_trained_model(task, model_name, input_size)\n",
    "            # Initialize XAI generator\n",
    "            xai_generator = XAIGenerator(model, model_name, input_size)\n",
    "            # Store results for this model\n",
    "            results[task][model_name] = {\n",
    "                'images': images,\n",
    "                'labels': labels,\n",
    "                \"mask_slices\": mask_slices,\n",
    "                'heatmaps': []\n",
    "            }\n",
    "            # Process each image with filename\n",
    "            for idx, (image, label, filename, mask_slice) in enumerate(zip(images, labels, filenames, mask_slices)):\n",
    "                #print(f\"Processing image {idx+1}/{len(images)} (Label: {label}, File: {filename})\")\n",
    "                # Preprocess image\n",
    "                image_tensor = preprocess_image(image, processor, input_size)\n",
    "                # Generate all heatmaps for this image\n",
    "                heatmaps = xai_generator.generate_all_heatmaps(image_tensor, target_class=label)\n",
    "                results[task][model_name]['heatmaps'].append(heatmaps)\n",
    "                for xai_name, heatmap in heatmaps.items():\n",
    "                    overlay = overlay_heatmap_on_image(image, heatmap, mask_slice)\n",
    "                    if DRAW_LAYER:\n",
    "                        overlay = add_layer_line(overlay, mask_slice)\n",
    "                    # overlay is np.uint8 HxWx3 per implementation\n",
    "                    # Create directory structure: ./heatmap_results/<task_name>/<label_idx>/<image_name>/<baselinemodel>/<XAI>.jpg\n",
    "                    save_dir = Path(heatmap_dir) / task / str(label) / filename / model_name\n",
    "                    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "                    out_path = save_dir / f\"{xai_name}.jpg\"\n",
    "                    try:\n",
    "                        if not isinstance(overlay, Image.Image):\n",
    "                            overlay = Image.fromarray(overlay)\n",
    "                        overlay.save(out_path, format='JPEG', quality=95)\n",
    "                        # Save the heatmap as numpy array\n",
    "                        np.save(save_dir / f\"{xai_name}.npy\", heatmap)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to save {out_path}: {e}\")\n",
    "            print(f\"Completed {model_name} for {task}\")\n",
    "            #delete after finish\n",
    "            del xai_generator\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cc020db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing New Heatmap Generation Function ===\n",
      "This will save heatmaps in the structure: ./heatmap_results/<task_name>/<label_idx>/<image_name>/<baselinemodel>/<XAI>.jpg\n",
      "Starting comprehensive heatmap generation...\n",
      "Tasks: ['DME']\n",
      "Models: ['ResNet-50', 'timm_efficientnet-b4']\n",
      "Samples per task: -1\n",
      "\n",
      "=== Processing Task: DME ===\n",
      "After adding mask, data len:  199\n",
      "Loaded 199 images for DME\n",
      "\n",
      "--- Processing Model: ResNet-50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb916084e614276a5846df343be54fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([2, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume checkpoint /orange/ruogu.fang/tienyuchang/RETfound_results/DME_binary_all_split-IRB2024_v5-all-microsoft/resnet-50-OCT-bs16ep50lr5e-4optadamw-defaulteval-trsub0---add_mask---train_no_aug/checkpoint-best.pth for ResNet-50 on DME\n",
      "✓ CRP_LXT initialized for ResNet-50\n",
      "Completed ResNet-50 for DME\n",
      "\n",
      "--- Processing Model: timm_efficientnet-b4 ---\n",
      "Resume checkpoint /orange/ruogu.fang/tienyuchang/RETfound_results/DME_binary_all_split-IRB2024_v5-all-timm_efficientnet-b4-OCT-bs16ep50lr5e-4optadamw-defaulteval-trsub0---add_mask---train_no_aug/checkpoint-best.pth for timm_efficientnet-b4 on DME\n",
      "✓ CRP_LXT initialized for timm_efficientnet-b4\n",
      "Completed timm_efficientnet-b4 for DME\n"
     ]
    }
   ],
   "source": [
    "# Test the new function with improved directory structure\n",
    "print(\"=== Testing New Heatmap Generation Function ===\")\n",
    "print(\"This will save heatmaps in the structure: ./heatmap_results/<task_name>/<label_idx>/<image_name>/<baselinemodel>/<XAI>.jpg\")\n",
    "\n",
    "# Test with a small number of samples first\n",
    "#Model_list = ['ResNet-50', 'timm_efficientnet-b4', 'vit-base-patch16-224', 'RETFound_mae']\n",
    "heatmap_results_v2 = generate_comprehensive_heatmaps_v2(num_samples=-1,task_list=Task_list,model_list=['ResNet-50', 'timm_efficientnet-b4'],heatmap_dir=\"./heatmap_results_modelmask\")  # Start with 3 samples for testing\n",
    "#heatmap_results_v2 = generate_comprehensive_heatmaps_v2(num_samples=1,task_list=['DME'],model_list=['ResNet-50'])  # Start with 3 samples for testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5c2ac1-dd25-4bb0-8c23-46f7e023d416",
   "metadata": {},
   "source": [
    "# Summaries heatmap value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "287519e8-dd8e-4f12-ab67-583bbb2aa076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "def read_grid_center(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    cx = int(float(root.findtext(\".//center/x\")))\n",
    "    cz = int(float(root.findtext(\".//center/z\")))\n",
    "    return cx, cz\n",
    "\n",
    "LAYER_LIST = ['ILM (ILM)', 'RNFL-GCL (RNFL-GCL)', 'GCL-IPL (GCL-IPL)', 'IPL-INL (IPL-INL)', 'INL-OPL (INL-OPL)', 'OPL-Henles fiber layer (OPL-HFL)', 'Boundary of myoid and ellipsoid of inner segments (BMEIS)', 'IS/OS junction (IS/OSJ)', 'Inner boundary of OPR (IB_OPR)', 'Inner boundary of RPE (IB_RPE)', 'Outer boundary of RPE (OB_RPE)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d846e97-a48e-4fe6-a6c2-8426e3a108d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_layer_statistics(heatmap, mask_slice):\n",
    "    \"\"\"\n",
    "    Divide heatmap into layers based on mask_slice and calculate statistics\n",
    "    Includes background region (pixels outside all layers)\n",
    "    \n",
    "    Args:\n",
    "        heatmap: 2D numpy array (H, W)\n",
    "        mask_slice: 2D numpy array (num_layers, W) - layer boundaries\n",
    "    \n",
    "    Returns:\n",
    "        list: Statistics for each layer + background (mean, max, sum, count)\n",
    "        float: Total heatmap sum for percentage calculation\n",
    "    \"\"\"\n",
    "    if heatmap is None or mask_slice is None:\n",
    "        return None, 0.0\n",
    "    heatmap = normalize_heatmap(heatmap)\n",
    "    num_layers = mask_slice.shape[0] - 1  # Number of layers between boundaries\n",
    "    stats = []\n",
    "    \n",
    "    # Create a mask to track which pixels belong to layers\n",
    "    layer_mask = np.zeros_like(heatmap, dtype=bool)\n",
    "    \n",
    "    # Calculate stats for each layer\n",
    "    for layer_idx in range(num_layers):\n",
    "        upper = mask_slice[layer_idx].astype(int)\n",
    "        lower = mask_slice[layer_idx + 1].astype(int)\n",
    "        \n",
    "        # Collect all pixel values in this layer\n",
    "        layer_pixels = []\n",
    "        for x in range(min(heatmap.shape[1], mask_slice.shape[1])):\n",
    "            y_start = max(0, min(upper[x], heatmap.shape[0]))\n",
    "            y_end = max(0, min(lower[x], heatmap.shape[0]))\n",
    "            if y_end > y_start:\n",
    "                layer_pixels.extend(heatmap[y_start:y_end, x].flatten())\n",
    "                # Mark these pixels as part of a layer\n",
    "                layer_mask[y_start:y_end, x] = True\n",
    "        \n",
    "        if len(layer_pixels) > 0:\n",
    "            layer_pixels = np.array(layer_pixels)\n",
    "            stats.append({\n",
    "                'mean': np.mean(layer_pixels),\n",
    "                'max': np.max(layer_pixels),\n",
    "                'sum': np.sum(layer_pixels),\n",
    "                'count': len(layer_pixels)\n",
    "            })\n",
    "        else:\n",
    "            stats.append({\n",
    "                'mean': 0.0,\n",
    "                'max': 0.0,\n",
    "                'sum': 0.0,\n",
    "                'count': 0\n",
    "            })\n",
    "    \n",
    "    # Calculate background (pixels outside all layers)\n",
    "    background_pixels = heatmap[~layer_mask]\n",
    "    if len(background_pixels) > 0:\n",
    "        stats.append({\n",
    "            'mean': np.mean(background_pixels),\n",
    "            'max': np.max(background_pixels),\n",
    "            'sum': np.sum(background_pixels),\n",
    "            'count': len(background_pixels)\n",
    "        })\n",
    "    else:\n",
    "        stats.append({\n",
    "            'mean': 0.0,\n",
    "            'max': 0.0,\n",
    "            'sum': 0.0,\n",
    "            'count': 0\n",
    "        })\n",
    "    \n",
    "    # Calculate total sum for percentage\n",
    "    total_sum = np.sum(heatmap)\n",
    "    \n",
    "    return stats, total_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58064971-2153-4d18-9f86-201005596d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_heatmap_and_mask_from_files(task, label, filename, model_name, xai_method, heatmap_dir, \n",
    "                                      thickness_dir, thickness_df, dataset_dir=None):\n",
    "    \"\"\"\n",
    "    Load heatmap from .npy file, corresponding mask_slice, and original image\n",
    "    \n",
    "    Args:\n",
    "        task: Task name\n",
    "        label: Label index\n",
    "        filename: Image filename (without extension, e.g., 'folder_13')\n",
    "        model_name: Model name\n",
    "        xai_method: XAI method name\n",
    "        heatmap_dir: Base directory for heatmaps\n",
    "        thickness_dir: Directory containing thickness data\n",
    "        thickness_df: dataframe with thickness mapping\n",
    "        dataset_dir: Dataset directory (optional, uses global if None)\n",
    "    \n",
    "    Returns:\n",
    "        heatmap: 2D numpy array or None\n",
    "        mask_slice: 2D numpy array or None\n",
    "        image_size: tuple (width, height) or None\n",
    "    \"\"\"\n",
    "    # Load heatmap\n",
    "    heatmap_path = Path(heatmap_dir) / task / str(label) / filename / model_name / f\"{xai_method}.npy\"\n",
    "    if not heatmap_path.exists():\n",
    "        return None, None, None\n",
    "    \n",
    "    try:\n",
    "        heatmap = np.load(heatmap_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading heatmap from {heatmap_path}: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Load original image to get size\n",
    "    image_size = None\n",
    "    if dataset_dir is None:\n",
    "        # Use global variable if available\n",
    "        try:\n",
    "            dataset_dir_local = globals().get('dataset_dir', '/blue/ruogu.fang/tienyuchang/OCT_EDA')\n",
    "        except:\n",
    "            dataset_dir_local = '/blue/ruogu.fang/tienyuchang/OCT_EDA'\n",
    "    else:\n",
    "        dataset_dir_local = dataset_dir\n",
    "    \n",
    "    try:\n",
    "        # Reconstruct original image filename with extension\n",
    "        # filename is like \"foldername_13\", we need to find the actual image file\n",
    "        # In load_sample_data, filename comes from row['OCT'] and image is stored as label_X/filename\n",
    "        img_p_fmt = \"label_%d/%s\"\n",
    "        \n",
    "        # Try common image extensions\n",
    "        for ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "            img_path = os.path.join(dataset_dir_local, f\"{task}_sampled\", img_p_fmt % (label, filename + ext))\n",
    "            if os.path.exists(img_path):\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                image_size = img.size  # (width, height)\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load image for size: {e}\")\n",
    "        image_size = None\n",
    "    \n",
    "    # Load mask_slice\n",
    "    # Read thickness CSV to find the Surface Name\n",
    "    try:\n",
    "        # Find matching entry - filename should match the folder\n",
    "        matching_rows = thickness_df[thickness_df['OCT'].str.contains(filename, na=False)]\n",
    "        \n",
    "        row = matching_rows.iloc[0]\n",
    "        surface_name = row['Surface Name']\n",
    "        folder = row['folder']\n",
    "        \n",
    "        # Load mask\n",
    "        mask_path = os.path.join(thickness_dir, folder, surface_name)\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Mask file not found: {mask_path}\")\n",
    "            return heatmap, None, image_size\n",
    "        \n",
    "        mask = np.load(mask_path)  # (Layer, slice, W)\n",
    "        \n",
    "        # Extract slice index from filename\n",
    "        slice_index = int(filename.split(\"_\")[-1])\n",
    "        mask_slice = mask[:, slice_index, :]  # shape: (Layer, W)\n",
    "        \n",
    "        return heatmap, mask_slice, image_size\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading mask for {filename}: {e}\")\n",
    "        return heatmap, None, image_size\n",
    "\n",
    "\n",
    "def save_heatmap_statistics_to_csv(task_list, model_list, \n",
    "                                    heatmap_dir=\"./heatmap_results\",\n",
    "                                    dataset_dir=None,\n",
    "                                    thickness_dir=None,\n",
    "                                    thickness_csv=None,\n",
    "                                    output_csv=\"heatmap_layer_statistics.csv\"):\n",
    "    \"\"\"\n",
    "    Calculate statistics for each layer region by loading heatmaps and masks from files\n",
    "    \n",
    "    Args:\n",
    "        task_list: List of tasks\n",
    "        model_list: List of models\n",
    "        heatmap_dir: Directory where heatmaps are stored\n",
    "        dataset_dir: Dataset directory containing original images\n",
    "        thickness_dir: Directory containing thickness/mask data\n",
    "        thickness_csv: CSV file with thickness mapping\n",
    "        output_csv: Output CSV filename\n",
    "    \"\"\"\n",
    "    \n",
    "    if thickness_dir is None:\n",
    "        thickness_dir = Thickness_DIR\n",
    "    if thickness_csv is None:\n",
    "        thickness_csv = Thickness_CSV\n",
    "    if dataset_dir is None:\n",
    "        dataset_dir = globals().get('dataset_dir', '/blue/ruogu.fang/tienyuchang/OCT_EDA')\n",
    "    \n",
    "    all_records = []\n",
    "    xai_methods = ['GradCAM', 'ScoreCAM', 'RISE', 'Attention', 'CRP_LXT']\n",
    "    \n",
    "    print(f\"Processing statistics for {len(task_list)} tasks and {len(model_list)} models...\")\n",
    "    print(f\"Loading heatmaps from: {heatmap_dir}\")\n",
    "    print(f\"Loading images from: {dataset_dir}\")\n",
    "    print(f\"Loading masks from: {thickness_dir}\")\n",
    "    \n",
    "    for task in tqdm(task_list, desc=\"Tasks\"):\n",
    "        dataset_fname = 'sampled_labels01.csv'\n",
    "        df = pd.read_csv(os.path.join(dataset_dir, \"%s_sampled\"%task, dataset_fname))\n",
    "        thickness_df = pd.read_csv(thickness_csv).dropna(subset=['Surface Name'])\n",
    "        thickness_df = thickness_df.rename(columns={'OCT':'folder'})\n",
    "        thickness_df = df.merge(thickness_df,on='folder',how='inner').reset_index(drop=True)\n",
    "        task_path = Path(heatmap_dir) / task\n",
    "        if not task_path.exists():\n",
    "            print(f\"Task directory not found: {task_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Iterate through label directories\n",
    "        for label_dir in task_path.iterdir():\n",
    "            if not label_dir.is_dir():\n",
    "                continue\n",
    "            label = int(label_dir.name)\n",
    "            \n",
    "            # Iterate through sample directories\n",
    "            for sample_dir in tqdm(list(label_dir.iterdir()), desc=f\"Label {label}\", leave=False):\n",
    "                if not sample_dir.is_dir():\n",
    "                    continue\n",
    "                \n",
    "                filename = sample_dir.name\n",
    "                \n",
    "                # Iterate through models\n",
    "                for model_name in model_list:\n",
    "                    model_dir = sample_dir / model_name\n",
    "                    if not model_dir.exists():\n",
    "                        continue\n",
    "                    \n",
    "                    # Process each XAI method\n",
    "                    for xai_method in xai_methods:\n",
    "                        # Load heatmap, mask, and get image size\n",
    "                        heatmap, mask_slice, image_size = load_heatmap_and_mask_from_files(\n",
    "                            task, label, filename, model_name, xai_method,\n",
    "                            heatmap_dir, thickness_dir, thickness_df, dataset_dir\n",
    "                        )\n",
    "                        \n",
    "                        if heatmap is None or mask_slice is None:\n",
    "                            continue\n",
    "                        \n",
    "                        # Resize heatmap to match image size if we have it\n",
    "                        if image_size is not None:\n",
    "                            # image_size is (width, height), cv2.resize expects (width, height)\n",
    "                            heatmap_resized = cv2.resize(heatmap, image_size)\n",
    "                        else:\n",
    "                            heatmap_resized = heatmap\n",
    "                        \n",
    "                        # Calculate statistics for each layer + background\n",
    "                        layer_stats, total_sum = calculate_layer_statistics(heatmap_resized, mask_slice)\n",
    "                        \n",
    "                        if layer_stats is None:\n",
    "                            continue\n",
    "                        \n",
    "                        num_layers = mask_slice.shape[0] - 1\n",
    "                        \n",
    "                        # Create records for each layer + background\n",
    "                        for layer_idx, stats in enumerate(layer_stats):\n",
    "                            # Determine if this is background or a regular layer\n",
    "                            if layer_idx < num_layers:\n",
    "                                layer_name = LAYER_LIST[layer_idx] if layer_idx < len(LAYER_LIST) else f\"Layer_{layer_idx}\"\n",
    "                            else:\n",
    "                                layer_name = \"Background\"\n",
    "                            \n",
    "                            # Calculate percentage of total importance\n",
    "                            percentage = (stats['sum'] / total_sum * 100) if total_sum > 0 else 0.0\n",
    "                            \n",
    "                            record = {\n",
    "                                'task': task,\n",
    "                                'model': model_name,\n",
    "                                'filename': filename,\n",
    "                                'label': label,\n",
    "                                'xai_method': xai_method,\n",
    "                                'layer_idx': layer_idx,\n",
    "                                'layer_name': layer_name,\n",
    "                                'mean': stats['mean'],\n",
    "                                'max': stats['max'],\n",
    "                                'sum': stats['sum'],\n",
    "                                'pixel_count': stats['count'],\n",
    "                                'importance_percentage': percentage,\n",
    "                                'image_width': image_size[0] if image_size else None,\n",
    "                                'image_height': image_size[1] if image_size else None\n",
    "                            }\n",
    "                            \n",
    "                            all_records.append(record)\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    df = pd.DataFrame(all_records)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nStatistics saved to {output_csv}\")\n",
    "    print(f\"Total records: {len(all_records)}\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c982c0f-cd38-4c5b-8557-6f3697422868",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing statistics for 1 tasks and 4 models...\n",
      "Loading heatmaps from: ./heatmap_results_modelmask\n",
      "Loading images from: /blue/ruogu.fang/tienyuchang/OCT_EDA\n",
      "Loading masks from: /orange/ruogu.fang/tienyuchang/IRB2024_OCT_thickness/Data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tasks:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Label 1:   0%|          | 0/99 [00:00<?, ?it/s]\u001b[A\n",
      "Label 1:   1%|          | 1/99 [00:27<45:32, 27.88s/it]\u001b[A\n",
      "Label 1:   2%|▏         | 2/99 [05:25<5:02:03, 186.84s/it]\u001b[A\n",
      "Label 1:   3%|▎         | 3/99 [07:55<4:31:27, 169.66s/it]\u001b[A\n",
      "Label 1:   4%|▍         | 4/99 [08:00<2:45:53, 104.77s/it]\u001b[A\n",
      "Label 1:   5%|▌         | 5/99 [08:02<1:46:00, 67.67s/it] \u001b[A\n",
      "Label 1:   6%|▌         | 6/99 [08:05<1:11:04, 45.85s/it]\u001b[A\n",
      "Label 1:   7%|▋         | 7/99 [08:08<48:43, 31.78s/it]  \u001b[A\n",
      "Label 1:   8%|▊         | 8/99 [12:35<2:41:31, 106.50s/it]\u001b[A\n",
      "Label 1:   9%|▉         | 9/99 [12:38<1:51:31, 74.35s/it] \u001b[A\n",
      "Label 1:  10%|█         | 10/99 [12:42<1:17:58, 52.57s/it]\u001b[A\n",
      "Label 1:  11%|█         | 11/99 [12:47<55:43, 38.00s/it]  \u001b[A\n",
      "Label 1:  12%|█▏        | 12/99 [12:49<39:05, 26.96s/it]\u001b[A\n",
      "Label 1:  13%|█▎        | 13/99 [16:00<1:50:04, 76.79s/it]\u001b[A\n",
      "Label 1:  14%|█▍        | 14/99 [16:05<1:17:52, 54.97s/it]\u001b[A\n",
      "Label 1:  15%|█▌        | 15/99 [18:10<1:46:28, 76.05s/it]\u001b[A\n",
      "Label 1:  16%|█▌        | 16/99 [29:37<5:59:54, 260.18s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Execute the statistics calculation and save to CSV\n",
    "# This loads heatmaps, images, and masks from files\n",
    "stats_df = save_heatmap_statistics_to_csv(\n",
    "    task_list=['DME'],\n",
    "    model_list=['ResNet-50', 'timm_efficientnet-b4', 'vit-base-patch16-224', 'RETFound_mae'],\n",
    "    heatmap_dir=\"./heatmap_results_modelmask\",\n",
    "    dataset_dir=dataset_dir,\n",
    "    thickness_dir=Thickness_DIR,\n",
    "    thickness_csv=Thickness_CSV,\n",
    "    output_csv=\"heatmap_layer_statistics_modelmask.csv\"\n",
    ")\n",
    "\n",
    "# Display first few rows and summary\n",
    "print(\"\\nFirst 20 rows of the statistics:\")\n",
    "print(stats_df.head(20))\n",
    "\n",
    "print(\"\\n\\nSummary by layer:\")\n",
    "print(stats_df.groupby('layer_name')[['mean', 'importance_percentage']].mean())\n",
    "\n",
    "print(\"\\n\\nSamples per XAI method:\")\n",
    "print(stats_df['xai_method'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e03a5-9836-4b6d-a050-89c6a1f9e9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octxai",
   "language": "python",
   "name": "octxai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
