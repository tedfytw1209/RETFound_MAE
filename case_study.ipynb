{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbb5203-5c25-46e9-9800-69fda108889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset\n",
    "from pytorch_grad_cam import run_dff_on_image, GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from typing import List, Callable, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088415c1-dba0-4047-aee5-53bc1fabac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    ViTImageProcessor, ViTForImageClassification,\n",
    "    AutoImageProcessor, EfficientNetForImageClassification,\n",
    "    ResNetForImageClassification, AutoModel\n",
    ")\n",
    "import models_vit as models\n",
    "\n",
    "#get model\n",
    "def get_model(task,model,input_size,nb_classes):\n",
    "    if 'ADCon' in task:\n",
    "        id2label = {0: \"control\", 1: \"ad\"}\n",
    "        label2id = {v: k for k, v in id2label.items()}\n",
    "    else:\n",
    "        id2label = {i: f\"class_{i}\" for i in range(nb_classes)}\n",
    "        label2id = {v: k for k, v in id2label.items()}\n",
    "    processor = None\n",
    "    if 'RETFound_mae' in model:\n",
    "        model = models.__dict__['RETFound_mae'](\n",
    "        img_size=input_size,\n",
    "        num_classes=nb_classes,\n",
    "        drop_path_rate=0.2,\n",
    "        global_pool=True,\n",
    "    )\n",
    "    elif 'vit-base-patch16-224' in model:\n",
    "            # ViT-base-patch16-224 preprocessor\n",
    "            model_ = 'google/vit-base-patch16-224'\n",
    "            processor = TransformWrapper(ViTImageProcessor.from_pretrained(model_))\n",
    "            model = ViTForImageClassification.from_pretrained(\n",
    "                model_,\n",
    "                image_size=input_size, #Not in tianhao code, default 224\n",
    "                num_labels=nb_classes,\n",
    "                hidden_dropout_prob=0.0, #Not in tianhao code, default 0.0\n",
    "                attention_probs_dropout_prob=0.0, #Not in tianhao code, default 0.0\n",
    "                id2label=id2label,\n",
    "                label2id=label2id,\n",
    "                ignore_mismatched_sizes=True\n",
    "            )\n",
    "    elif 'efficientnet-b4' in model:\n",
    "        # EfficientNet-B4 preprocessor\n",
    "        model_ = 'google/efficientnet-b4'\n",
    "        processor = TransformWrapper(AutoImageProcessor.from_pretrained(model_))\n",
    "        model = EfficientNetForImageClassification.from_pretrained(\n",
    "            model_,\n",
    "            image_size=input_size,\n",
    "            num_labels=nb_classes,\n",
    "            dropout_rate=0.0,\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "    elif 'resnet-50' in model:\n",
    "        model_name = 'microsoft/resnet-50'\n",
    "        processor = TransformWrapper(AutoImageProcessor.from_pretrained(model_name))\n",
    "        model = ResNetForImageClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=nb_classes,\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "\n",
    "    return model, processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f0a85-078e-4a03-a4f7-57bf8778c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task and dataset\n",
    "Task_list = ['ADCon','DME']\n",
    "dataset_fname = 'sampled_labels01.csv'\n",
    "dataset_dir = '/blue/ruogu.fang/tienyuchang/OCT_EDA'\n",
    "img_p_fmt = \"label_%d/%s\" #label index and oct_img name\n",
    "\n",
    "# model\n",
    "Model_list = ['ResNet-50', 'efficientnet-b4', 'vit-base-patch16-224', 'RETFound_mae']\n",
    "ADCon_finetuned = [\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"ad_control_detect_data-IRB2024v5_ADCON_DL_data-all-RETFound_mae-OCT-defaulteval---bal_sampler-/\"\n",
    "]\n",
    "DME_finetuned = [\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"DME_binary_all_split-IRB2024_v5-all-google/vit-base-patch16-224-in21k-OCT-bs16ep50lr5e-4optadamw-defaulteval-trsub0--/\",\n",
    "    \"DME_binary_all_split-IRB2024_v5-all-RETFound_mae_natureOCT-OCT-bs16ep50lr5e-4optadamw-roc_auceval-trsub0--/\"\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octxai",
   "language": "python",
   "name": "octxai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
